{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Nodes for Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>assigned</th>\n",
       "      <th>mtaTypeStatId</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>mikeStationId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>tr101</td>\n",
       "      <td>40.889377</td>\n",
       "      <td>-73.898421</td>\n",
       "      <td>butr0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type  assigned mtaTypeStatId        lat       long mikeStationId\n",
       "0   tr         0         tr101  40.889377 -73.898421         butr0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv('../data/finalround/unreducedStops.csv', nrows=1000)\n",
    "stops_dropped = raw.drop(['Unnamed: 0', 'id'], axis=1)\n",
    "stops_dropped.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create Edges for Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mta_stop_id</th>\n",
       "      <th>mta_start_id</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr902N</td>\n",
       "      <td>tr901N</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mta_stop_id mta_start_id  duration\n",
       "0      tr902N       tr901N       1.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips = pd.read_csv('../data/finalround/busTrainTrips.csv', nrows=1000)\n",
    "trips_dropped = trips.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "def concatenatorator2(x):\n",
    "    tmp = str()\n",
    "    if x == \"bikeStop\":\n",
    "        tmp = 'bi'\n",
    "    elif x == \"busStop\":\n",
    "        tmp = 'bu'\n",
    "    elif x == \"trainStop\":\n",
    "        tmp = 'tr'\n",
    "    return tmp\n",
    "\n",
    "# use the raw loaded data to create a complete list of all\n",
    "# mta station ids and mike's assigned ids\n",
    "# this is different then the groupby approach above.\n",
    "trips_dropped['type2'] = trips_dropped['type'].apply(concatenatorator2)\n",
    "trips_dropped['type'] = trips_dropped['type2']\n",
    "trips_dropped['mta_stop_id'] = trips_dropped['type']+trips_dropped['mta_stop_id'].astype(str)\n",
    "trips_dropped['mta_start_id'] = trips_dropped['type']+trips_dropped['mta_start_id'].astype(str)\n",
    "trips_dropped.drop(['type2', 'type'], axis=1, inplace=True)\n",
    "trips_dropped.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print stops_dropped[stops_dropped['mtaTypeStatId']=='901N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join the groupby of mikes id and the complete list of mta stations\n",
    "joined_dfs = trips_dropped.merge(stops_dropped, how='left', left_on='mta_stop_id', right_on='mtaTypeStatId')\n",
    "\n",
    "joined_dfs.to_csv('/Users/matthewdunn/Dropbox/NYU/Spring2016/BigData/GroupProject/data/prepped_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_dfs_dropped = joined_dfs.drop(['id', 'type', 'assigned', 'mtaTypeStatId'], axis=1)\n",
    "joined_dfs_grouped = joined_dfs_dropped.groupby('mikeStationId').mean()\n",
    "joined_dfs_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import json\n",
    "from shapely.geometry import shape, Point\n",
    "with open('/Users/matthewdunn/Dropbox/NYU/Spring2016/BigData/GroupProject/nyccensustracts.json', 'r') as f:\n",
    "    js = json.load(f)\n",
    "\n",
    "\n",
    "def geocoder(lat, lon):\n",
    "    point = Point(lon, lat)\n",
    "\n",
    "    # check each polygon to see if it contains the point\n",
    "    for feature in js['features']:\n",
    "        geometry = feature.get('geometry')\n",
    "        polygon = shape(geometry)\n",
    "        if polygon.contains(point):\n",
    "                properties = feature.get('properties')\n",
    "                census_tract = properties.get('BoroCT2010')\n",
    "                return census_tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "censustracts = []\n",
    "for i, row in joined_dfs_grouped.iterrows():\n",
    "    censustract = geocoder(row.lat, row['long'])\n",
    "    censustracts.append(censustract)\n",
    "censustracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allpairsBus = pd.read_csv(\"./data/allPairDistancesBusTrain.csv\")\n",
    "allpairsBus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allpairsBus_drop = allpairsBus.drop(['assigned', 'Unnamed: 0.1'], 1)\n",
    "allpairsBus_drop = allpairsBus_drop.drop([0, 1])\n",
    "cols = list(allpairsBus_drop.columns.values)\n",
    "cols = cols[1:]\n",
    "duration_df = pd.melt(allpairsBus_drop, id_vars=['Unnamed: 0'], value_vars=cols)\n",
    "duration_df.columns = ['mikestartId', 'mikeendId', 'duration']\n",
    "duration_df = duration_df[duration_df.mikestartId != duration_df.mikeendId]\n",
    "duration_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_dfs_grouped['censustract'] = censustracts\n",
    "joined_dfs_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_duration = duration_df.merge(joined_dfs_grouped, how='left', left_on='mikestartId', right_index=True)\n",
    "merged_duration.columns = ['mikestartId','mikeendId','duration','start_lat','start_long','start_censustract']\n",
    "merged_duration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_duration_final = merged_duration.merge(joined_dfs_grouped, how='left', left_on='mikeendId', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_duration_final.columns = ['mikestartId','mikeendId','duration','start_lat','start_long','start_censustract','end_lat','end_long','end_censustract']\n",
    "merged_duration_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from haversine import haversine\n",
    "def manhattandist(start_lat, start_lon, end_lat, end_lon):\n",
    "    start_station_location = (start_lat, start_lon)\n",
    "    end_station_location = (end_lat, end_lon)\n",
    "    return haversine(start_station_location, end_station_location, miles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances = []\n",
    "for i, row in merged_duration_final.iterrows():\n",
    "    distance = manhattandist(row.start_lat, row.start_long, row.end_lat, row.end_long)\n",
    "    distances.append(distance)\n",
    "len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_duration_final['distance'] = distances\n",
    "merged_duration_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_duration_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_duration_final.to_csv('/Users/matthewdunn/Dropbox/NYU/Spring2016/BigData/GroupProject/data/mikeCTsAvgLatLonDist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Create the Bus Sheet for Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_raw = pd.read_csv('/Users/matthewdunn/Dropbox/NYU/Spring2016/BigData/GroupProject/data/mta_bus/mergedRoutesStops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trips_dropped = merged_raw.drop(['Unnamed: 0', 'trip_id', 'start_lat', 'start_lon', 'end_lon', 'end_lat', 'arrival_time', 'departure_time'], axis=1)\n",
    "trips_dropped['end_location_id'] = trips_dropped['end_location_id'].astype(int)\n",
    "trips_dropped['start_mtaTypeStatId'] = 'bu'+trips_dropped['start_location_id'].astype(str)\n",
    "trips_dropped['end_mtaTypeStatId'] = 'bu'+trips_dropped['end_location_id'].astype(str)\n",
    "trips_dropped.drop(['end_location_id', 'start_location_id'], axis=1, inplace=True)\n",
    "print trips_dropped.head()\n",
    "trips_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dedupe the Merge Key between MTA and Mikes ID\n",
    "joined_deduped = joined_dfs.drop_duplicates()\n",
    "print joined_deduped.head()\n",
    "# Create a Start Station Version\n",
    "startStation = joined_deduped[['mtaTypeStatId','lat','long','mikeStationId']].copy()\n",
    "startStation.columns = ['start_mtaTypeStatId','start_lat','start_long','start_mikeStationId']\n",
    "# Create an End Station Version\n",
    "endStation = joined_deduped[['mtaTypeStatId','lat','long','mikeStationId']].copy()\n",
    "endStation.columns = ['end_mtaTypeStatId','end_lat','end_long','end_mikeStationId']\n",
    "print endStation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# validating shit works\n",
    "# joined_deduped.loc[joined_deduped.id == '901N']\n",
    "# print any(joined_deduped.mtaTypeStatId == 'bu901N')\n",
    "# print any(startStation.start_mtaTypeStatId == '901N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final = pd.merge(trips_dropped, startStation, on='start_mtaTypeStatId', how='left')\n",
    "final2 = final.merge(endStation, how='left', left_on='end_mtaTypeStatId', right_on='end_mtaTypeStatId')\n",
    "final2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fianl2_dropped = final2.drop(['start_mtaTypeStatId', 'end_mtaTypeStatId', 'start_lat', 'start_long','end_lat', 'end_long'], axis=1)\n",
    "print fianl2_dropped.head()\n",
    "print fianl2_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fianl2_dropped['key'] = fianl2_dropped['start_mikeStationId']+'_'+fianl2_dropped['end_mikeStationId']\n",
    "mapreduce = fianl2_dropped.drop(['start_mikeStationId', 'end_mikeStationId'], axis=1)\n",
    "mapreduce = mapreduce[['key', 'duration']]\n",
    "mapreduce['duration'] = mapreduce['duration']*60\n",
    "print mapreduce.head()\n",
    "print mapreduce.shape\n",
    "mapreduce.to_csv('/Users/matthewdunn/Dropbox/NYU/Spring2016/BigData/GroupProject/data/mta_bus/mapreduce.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used to write out small sample files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shorter = pd.read_csv('/Users/matthewdunn/Dropbox/NYU/Spring2016/BigData/GroupProject/data/allPairDistancesBusTrain.csv', nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shorter.to_csv('/Users/matthewdunn/Dropbox/NYU/Spring2016/BigData/GroupProject/data/allPairDistancesBusTrain_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now Create the Train Sheet for Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_raw_train = pd.read_csv('/Users/matthewdunn/Dropbox/NYU/Spring2016/BigData/GroupProject/data/mta_train/mergedTrainRoutesStops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_raw_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trips_dropped_train = merged_raw_train.drop(['Unnamed: 0', 'trip_id', 'start_lat', 'start_lon', 'end_lon', 'end_lat', 'arrival_time', 'departure_time'], axis=1)\n",
    "# trips_dropped_train['end_location_id'] = trips_dropped_train['end_location_id'].astype(int)\n",
    "trips_dropped_train['start_mtaTypeStatId'] = 'tr'+trips_dropped_train['start_location_id'].astype(str)\n",
    "trips_dropped_train['end_mtaTypeStatId'] = 'tr'+trips_dropped_train['end_location_id'].astype(str)\n",
    "trips_dropped_train.drop(['end_location_id', 'start_location_id'], axis=1, inplace=True)\n",
    "print trips_dropped_train.head()\n",
    "print trips_dropped_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "any(joined_dfs.mtaTypeStatId == 'tr901N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_train = pd.merge(trips_dropped_train, startStation, on='start_mtaTypeStatId', how='left')\n",
    "final2_train = final_train.merge(endStation, how='left', left_on='end_mtaTypeStatId', right_on='end_mtaTypeStatId')\n",
    "final2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fianl2_train_dropped = final2_train.drop(['start_mtaTypeStatId', 'end_mtaTypeStatId', 'start_lat', 'start_long','end_lat', 'end_long'], axis=1)\n",
    "print fianl2_train_dropped.head()\n",
    "print fianl2_train_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fianl2_train_dropped['key'] = fianl2_train_dropped['start_mikeStationId']+'_'+fianl2_train_dropped['end_mikeStationId']\n",
    "mapreduce_train = fianl2_train_dropped.drop(['start_mikeStationId', 'end_mikeStationId'], axis=1)\n",
    "mapreduce_train = mapreduce_train[['key', 'duration']]\n",
    "mapreduce_train['duration'] = mapreduce_train['duration']*60\n",
    "print mapreduce_train.head()\n",
    "print mapreduce_train.shape\n",
    "mapreduce_train.to_csv('/Users/matthewdunn/Dropbox/NYU/Spring2016/BigData/GroupProject/data/mta_train/mapreduce.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bus_train_map_reduce = pd.concat([mapreduce_train, mapreduce], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print bus_train_map_reduce.head()\n",
    "print bus_train_map_reduce.shape\n",
    "bus_train_map_reduce.to_csv('/Users/matthewdunn/Dropbox/NYU/Spring2016/BigData/GroupProject/data/bus_train_mapreduce.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
