{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reformat(data):\n",
    "    '''\n",
    "    wrangle stop Times data to get start and stop times between each stop\n",
    "    '''\n",
    "    \n",
    "    reformattedData =  data.copy()\n",
    "    tempTime= data['departure_time'].ix[1:].values\n",
    "    times = pd.Series(tempTime)\n",
    "    times.append(pd.Series(['2']))\n",
    "\n",
    "    tempSequence = data['stop_sequence'].ix[1:].values\n",
    "    sequence= pd.Series(tempSequence)\n",
    "    sequence.append(pd.Series(['2']))\n",
    "\n",
    "    start_id = data['stop_id'].ix[1:].values\n",
    "    ids = pd.Series(start_id)\n",
    "    ids.append(pd.Series(['2']))\n",
    "\n",
    "    reformattedData['stop_sequence2'] =sequence\n",
    "    reformattedData['departure_time'] = times\n",
    "    reformattedData['stop_id'] = ids\n",
    "    reformattedData['start_id'] = data['stop_id']\n",
    "    \n",
    "    goodIndexes = (reformattedData['stop_sequence'] +1 == reformattedData['stop_sequence2'])\n",
    "    reformattedData = reformattedData[goodIndexes]\n",
    "    return reformattedData\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper functions for cleaning up time when day changes\n",
    "def hh_mm_ss2seconds(hh_mm_ss):\n",
    "    return reduce(lambda acc, x: acc*60 + x, map(int, hh_mm_ss.split(':')))\n",
    "\n",
    "def cleanTimes(t):\n",
    "    '''\n",
    "    input: duration\n",
    "    output: if duration < 0 , adds 24 hrs \n",
    "    '''\n",
    "    if t<0:\n",
    "        return t+ 24*60*60\n",
    "    else :\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://web.mta.info/developers/developer-data-terms.html#data\n",
    "# under GTFS schedule data, New York City Transit Bus and New York City Transit Train - last updated march 24 2016\n",
    "\n",
    "#bus data for stops and stop times\n",
    "brookStopTimes = pd.read_csv(\"./data/rawData/bus/google_transit_brooklyn/stop_times.txt\")\n",
    "queensStopTimes = pd.read_csv(\"./data/rawData/bus/google_transit_queens/stop_times.txt\")\n",
    "bronxStopTimes = pd.read_csv(\"./data/rawData/bus/google_transit_bronx/stop_times.txt\")\n",
    "manhattanStopTimes = pd.read_csv(\"./data/rawData/bus/google_transit_manhattan/stop_times.txt\")\n",
    "statStopTimes = pd.read_csv(\"./data/rawData/bus/google_transit_staten_island/stop_times.txt\")\n",
    "\n",
    "\n",
    "brookStops = pd.read_csv(\"./data/rawData/bus/google_transit_brooklyn/stops.txt\")\n",
    "queensStops = pd.read_csv(\"./data/rawData/bus/google_transit_queens/stops.txt\")\n",
    "bronxStops = pd.read_csv(\"./data/rawData/bus/google_transit_bronx/stops.txt\")\n",
    "manhattanStops = pd.read_csv(\"./data/rawData/bus/google_transit_manhattan/stops.txt\")\n",
    "statStops = pd.read_csv(\"./data/rawData/bus/google_transit_staten_island/stops.txt\")\n",
    "\n",
    "\n",
    "\n",
    "#all train data\n",
    "stopTimes = pd.read_csv(\"./data/rawData/train/google_transit/stop_times.txt\")\n",
    "stops = pd.read_csv(\"./data/rawData/train/google_transit/stops.txt\")\n",
    "routes = pd.read_csv(\"./data/rawData/train/google_transit/routes.txt\")\n",
    "trips = pd.read_csv(\"./data/rawData/train/google_transit/trips.txt\")\n",
    "\n",
    "\n",
    "#clean busTrips and trainTrips\n",
    "bronx= reformat(bronxStopTimes)\n",
    "stat= reformat(statStopTimes)\n",
    "man =reformat(manhattanStopTimes)\n",
    "queens = reformat(queensStopTimes)\n",
    "brook = reformat(brookStopTimes)\n",
    "\n",
    "allRoutesTrain = reformat(stopTimes)\n",
    "allRoutesTrain['type']=\"train\"\n",
    "\n",
    "\n",
    "allRoutesBus = pd.concat([bronx,stat,man,queens,brook])\n",
    "allRoutesBus['type']=\"bus\"\n",
    "\n",
    "\n",
    "busStops= pd.concat([brookStops,queensStops,bronxStops,manhattanStops,statStops])\n",
    "busStops['type']=\"busStop\"\n",
    "stops['type']=\"trainStop\"\n",
    "\n",
    "#combine all bus and train stops/trips\n",
    "allStops = pd.concat([stops,busStops])\n",
    "allRoutes = pd.concat([allRoutesTrain,allRoutesBus])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "result = pd.merge(allRoutes, allStops, on='stop_id')\n",
    "result.rename(columns = {'stop_lat':'dropoff_latitude' , 'stop_lon':'dropoff_longitude'}, inplace = True)\n",
    "result2 = pd.merge(result, allStops, left_on='start_id',right_on='stop_id')\n",
    "result2.rename(columns = {'stop_lat':'pickup_latitude' , 'stop_lon':'pickup_longitude'}, inplace = True)\n",
    "result2= result2[['trip_id','stop_id_x','start_id','type','arrival_time','departure_time']]\n",
    "result2.rename(columns = {'start_id':'mta_start_id','stop_id_x':'mta_stop_id'}, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compute duration of trip\n",
    "times = pd.DataFrame()\n",
    "times['ar'] = result2['arrival_time'].apply(lambda x:hh_mm_ss2seconds(x) )\n",
    "times['de'] = result2['departure_time'].apply(lambda x:hh_mm_ss2seconds(x) )\n",
    "times['dif']= times['de']-times['ar']\n",
    "#handle case where time stamp switched between days\n",
    "result2['duration'] = times['dif'].apply(lambda x: cleanTimes(x)/60.)\n",
    "\n",
    "\n",
    "result2 = result2[['mta_stop_id','mta_start_id','type','duration']]\n",
    "result2.to_csv('./data/mergedData/busTrainTrips.csv')\n",
    "\n",
    "allStops.rename(columns = {'stop_id':'id','stop_lat':'lat','stop_lon':'long'}, inplace = True)\n",
    "allStops =allStops[['id','lat','long','type']]\n",
    "\n",
    "allStops = allStops.reset_index()\n",
    "\n",
    "allStops.to_csv('/home/michael/Desktop/bigDataProject/finalVersion/data/mergedData/busTrainStops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stopReducer(data,radius):\n",
    "    '''\n",
    "    performs one pass through the stop locations, combining stops that are within the radius \n",
    "    (manhattan distance). If a stop is assigned it is not eligible to be assigned to a new group.\n",
    "    Basic function is to combine points that are close together\n",
    "    '''\n",
    "    reducerMap = dict()\n",
    "    \n",
    "    data['assigned'] = \"a\"\n",
    "    groupNumber =0\n",
    "    #data[mask]['assigned'].apply(lambda x:  False)\n",
    "    rowNumber = 0\n",
    "    while (data['assigned']==\"a\").sum()>0:  #continue until all of data has been assigned to a group\n",
    "        row = data.iloc[rowNumber]\n",
    "        if row['assigned']==\"a\":  # has not been assigned yet\n",
    "            \n",
    "            # create filter for \"close points\" so we don't have to look at all pairs\n",
    "            data[\"x\"] = data['lat'].apply(lambda x: np.absolute(x - row.lat))\n",
    "            data[\"y\"] = data['long'].apply(lambda x: np.absolute(x - row['long']))\n",
    "            data['L1'] = data[\"x\"] + data[\"y\"]\n",
    "            mask0= data['roughLatLon']==row.roughLatLon\n",
    "            mask1 = data['L1']<radius\n",
    "            \n",
    "            #only want to combine with other points that have not been assigned\n",
    "            mask2 = data['assigned']==\"a\"\n",
    "            \n",
    "            mask3 = np.logical_and(mask1, mask2)\n",
    "            mask4 = np.logical_and(mask3,mask0)\n",
    "            \n",
    "            data.ix[mask4,'assigned']=groupNumber\n",
    "            \n",
    "            groupNumber += 1\n",
    "        rowNumber +=1\n",
    "\n",
    "    \n",
    "    return   data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allStops['assigned']=\"a\" # mark unassigned rows\n",
    "allStops['roughLat']=allStops['lat'].apply(lambda x: float(int(x*100))/100)\n",
    "allStops['roughLon']=allStops['long'].apply(lambda x: float(int(x*100))/100)\n",
    "allStops['roughLatLon']=zip(allStops['roughLat'] , allStops['roughLon'])\n",
    "allStops['assigned']=\"a\"\n",
    "\n",
    "a = stopReducer(allStops,.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14201"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reducedStops = a[['lat','long','type','assigned','id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reducedStops = pd.to_csv('./data/mergedData/reducedStops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'lat', 'long', 'type'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allStops.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allStops2 = allStops.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'103S'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allStops2['id'][5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
